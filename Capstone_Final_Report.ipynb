{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Capstone Final Report",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# IEEE Fraud Detection\n",
        "\n",
        "### Team Members: Rishitha, Rohit Kumar Kovuri\n",
        "\n",
        "### Introduction to Fraud Detection\n",
        "In the landscape of digital finance, the rise of online transactions has also escalated the prevalence of fraudulent activities, posing significant challenges for both businesses and consumers. Fraudsters leverage sophisticated techniques to bypass security measures, executing unauthorized transactions that lead to substantial financial losses and erode trust in financial systems. In response to this growing threat, cutting-edge fraud detection systems, underpinned by machine learning algorithms, have become crucial. These systems scrutinize each transaction in real-time, employing a range of features to detect anomalies and prevent fraud before it inflicts harm.\n",
        "\n",
        "### Problem Statement\n",
        "The essence of our project is to formulate an effective fraud detection system that precisely identifies fraudulent transactions within a voluminous dataset of online financial activities. We are provided with a dataset that encompasses diverse features such as transaction amounts, timestamps, user demographics, device types, and behavioral patterns. Our challenge is to develop a predictive model that distinguishes legitimate transactions from fraudulent ones, aiming for high levels of precision and recall to ensure reliability and efficiency in fraud detection.\n",
        "\n",
        "#### Key Objectives\n",
        "- **Data Preparation**: Cleansing and consolidating data for analysis.\n",
        "- **Feature Selection**:\n",
        "  - **Numerical Features**: Identifying and utilizing quantitative data that influence the prediction accuracy.\n",
        "  - **Categorical Features**: Assessing and encoding qualitative data relevant to transaction authenticity.\n",
        "- **Data Preprocessing**: Transforming raw data into a format suitable for modeling, addressing issues like missing values and data scaling.\n",
        "- **Model Development**:\n",
        "  - **Logistic Regression Model**: Establishing a baseline with a simple yet effective approach.\n",
        "  - **Decision Tree Model**: Using tree-based methods to capture non-linear relationships.\n",
        "  - **Random Forest Model**: Enhancing decision trees with an ensemble method to improve prediction stability and accuracy.\n",
        "  - **Gradient Boosted Trees**: Applying a powerful boosting technique to minimize errors progressively.\n",
        "- **Model Selection**: Comparing different models based on performance metrics to select the most effective one for deployment.\n",
        "\n",
        "This structured approach will guide our investigation and development phases, ensuring that each step is aligned with the overarching goal of deploying a robust fraud detection system. The subsequent sections will delve into the methodologies employed in each objective, detail the challenges encountered, and discuss the solutions implemented to overcome these hurdles.\n"
      ],
      "metadata": {
        "id": "E2Y7ic6rnq8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objectives and Methodologies\n",
        "\n",
        "In addressing the challenge of fraud detection in online transactions, our project follows a systematic approach to ensure that each phase contributes effectively towards building a reliable model. Here’s a detailed breakdown of our key objectives and the methodologies employed in each:\n",
        "\n",
        "### . Data Preparation\n",
        "Data preparation is the foundational step in our project. We began by merging the transaction and identity datasets provided by IEEE-CIS to form a comprehensive view of each transaction. Next, we handled missing values and anomalies by imputing missing entries and removing outliers that could skew our model’s performance. This phase also involved feature engineering where new variables were derived from existing data to enhance the model's ability to detect fraud."
      ],
      "metadata": {
        "id": "48EIgV8inq8n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here’s a concise overview of the Python packages used in the project:\n",
        "\n",
        "- **os & gc**: Manage operating system interactions and garbage collection.\n",
        "- **pandas & numpy**: Handle data manipulation, analysis, and mathematical operations.\n",
        "- **matplotlib.pyplot**: Create various types of visualizations.\n",
        "- **sklearn**: Essential for data preprocessing and machine learning. This includes classes for handling missing data (`SimpleImputer`), automating workflows (`Pipeline`), transforming data (`ColumnTransformer`, `OneHotEncoder`, `MinMaxScaler`), and several models (`LogisticRegression`, `DecisionTreeClassifier`, `RandomForestClassifier`).\n",
        "- **xgboost**: Provides an implementation of the Gradient Boosting algorithm.\n",
        "- **Statistical Tests**: `chi2` and `chi2_contingency` for feature selection and testing variable independence.\n",
        "\n",
        "These tools collectively support all stages of the project from data preparation to modeling and evaluation."
      ],
      "metadata": {
        "id": "GAfHeFGenq8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the Train Data\n",
        "\n",
        "In this phase, we load the necessary datasets from the IEEE fraud detection competition. These datasets include both transaction and identity information, which are crucial for our analysis and model training. Below is a summary of the data loading process and the initial examination of the datasets:\n",
        "\n",
        "- **Data Loading**:\n",
        "  - `train_identity.csv` and `train_transaction.csv` are loaded for training the models. These files provide identity and transaction details respectively.\n",
        "  - Similarly, `test_identity.csv` and `test_transaction.csv` are loaded for testing the models.\n",
        "\n",
        "- **Data Dimensions**:\n",
        "  - The training identity dataset contains 144,233 entries and 41 features.\n",
        "  - The training transaction dataset includes 590,540 entries and 394 features.\n",
        "  - The test identity and transaction datasets similarly reflect extensive data, crucial for validating the model's performance.\n",
        "\n",
        "- **Initial Data Inspection**:\n",
        "  - A brief inspection of the first few rows of each dataset gives insights into the types of variables and potential challenges like missing values and categorical encoding.\n",
        "  - The `train_identity` dataset includes variables such as device type and browser used, which might require encoding and handling of missing data.\n",
        "  - The `train_transaction` dataset contains transaction-specific details like transaction amount and product code, which are directly related to the transaction's nature and potential for being fraudulent.\n",
        "\n",
        "This setup stage is critical as it establishes the data foundation upon which all further analyses and model training are built. Understanding the structure and challenges of the data early on aids in effective preprocessing and modeling."
      ],
      "metadata": {
        "id": "1pIXb0_Nnq8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:ed65b89d-ee67-49de-bfcc-96374962b98e.png)"
      ],
      "metadata": {
        "id": "ibmjuJpVnq8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploration and Analysis of the Train Identity Dataset\n",
        "\n",
        "The exploration of the `train_identity` dataset provides crucial insights into the distribution of features and their characteristics. Here’s a summary of the statistical analysis and the uniqueness of categorical features:\n",
        "\n",
        "#### Statistical Summary\n",
        "The dataset includes a variety of identity-related features, such as device information and identifiers specific to the transaction context. Key observations from the summary statistics include:\n",
        "- **TransactionID** is the unique identifier for each transaction and spans a specific range.\n",
        "- **id_01 to id_34**: These features represent a mixture of continuous and categorical variables related to user identity, with various distributions. For example:\n",
        "  - **id_01**: Ranges from -100 to 0, indicating a potential scoring or rating system.\n",
        "  - **id_02 to id_06**: Mostly numerical identifiers with a wide range of values, suggesting varying scales and perhaps different measures of user identity validation or risk.\n",
        "- Features like **id_03** and **id_04** have a large number of missing values, indicating that they might not be applicable for all transactions.\n",
        "- Certain identity metrics like **id_20** and **id_21** show a significant variation, which might be indicative of geographic or demographic factors.\n",
        "\n",
        "#### Categorical Features Uniqueness\n",
        "- **id_12 to id_38, DeviceType, DeviceInfo**: These features are categorical, with varying numbers of unique values. High-cardinality features like **id_31** (130 unique browser types) and **id_33** (260 unique screen resolutions) could pose challenges in modeling due to the wide range of categories.\n",
        "- **DeviceType** and **DeviceInfo** reveal two and 1786 unique values, respectively, highlighting the variety of devices used in the transactions.\n",
        "\n",
        "### Analysis Implications\n",
        "The exploration reveals several challenges and considerations for the next steps:\n",
        "1. **Handling Missing Values**: Features with a significant amount of missing data require careful handling, either by imputation or exclusion, depending on their relevance to fraud detection.\n",
        "2. **Categorical Feature Encoding**: High-cardinality categorical features need to be encoded efficiently to ensure they are manageable for machine learning models without losing essential information. Techniques such as frequency or target encoding might be more suitable than one-hot encoding.\n",
        "3. **Feature Selection**: Given the large number of features, it's critical to identify and retain those that are most predictive of fraud to optimize model performance and computational efficiency.\n",
        "\n",
        "This initial data exploration sets the stage for more detailed data cleaning, feature engineering, and model development, which will focus on leveraging these insights to build a robust fraud detection system."
      ],
      "metadata": {
        "id": "EP64O4AGnq8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that only a small portion (around 3.5%) of transactions are fraudulent, while the vast majority (about 96.5%) are not. This is typical in fraud detection, but it means we need to be careful with our analysis so we don't miss those rare fraudulent cases. We'll use special methods to make sure our fraud detection system is sensitive to catching these rare but important events.\n",
        "\n",
        "![image.png](attachment:b07ed4e4-5dbf-4bd6-93e5-16d059c95f20.png)\n",
        "\n",
        "![image.png](attachment:77143b82-cb7a-4752-9f0f-fb48f648e9dc.png)"
      ],
      "metadata": {
        "id": "d3tWsEsGnq8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Selection for Fraud Detection Model\n",
        "\n",
        "**Numerical Features**:\n",
        "For our model, we've chosen a comprehensive set of 349 numerical features, including transaction amounts, distances, counts (like C1-C14), time deltas (like D1-D15), and many others, to capture the quantitative aspects of each transaction.\n",
        "\n",
        "**Categorical Features**:\n",
        "We've identified 49 categorical features such as product codes, card types, email domains, and device information, which add context and details to the transaction data.\n",
        "\n",
        "**Evaluation of Categorical Features**:\n",
        "To understand which categorical features are most related to fraud, we ran statistical tests on each feature. For instance, we analyzed the 'P_emaildomain' feature to see if certain email domains are more associated with fraud than others. We found that domains like 'gmail.com', 'yahoo.com', and 'hotmail.com' showed a significant relationship with fraudulent transactions, especially when they were present in over 1,000 transactions.\n",
        "\n",
        "This careful selection and evaluation of features are crucial to ensure our model can accurately identify patterns and signals indicative of fraudulent activity, while also being computationally efficient."
      ],
      "metadata": {
        "id": "PZhwibr2nq8x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing for Fraud Detection Model\n",
        "\n",
        "**Preprocessing Steps**:\n",
        "1. **Combining Features**: We combined 49 categorical and 349 numerical features for our model, totaling 398 features.\n",
        "2. **Numerical Transformation**: Applied a two-step process:\n",
        "   - **Imputation**: Replaced missing numerical values with the mean of each feature.\n",
        "   - **Scaling**: Adjusted the values to a common scale without distorting differences in the ranges using MinMaxScaler.\n",
        "3. **Categorical Transformation**: Also a two-step process:\n",
        "   - **Imputation**: Filled missing categorical values with 'NA'.\n",
        "   - **One-Hot Encoding**: Transformed categorical variables into a format that could be provided to machine learning algorithms to do a better job in prediction.\n",
        "\n",
        "**Fitting the Preprocessor**:\n",
        "- The preprocessor, which includes both the numerical and categorical pipelines, was fitted to our training data. This is a crucial step to transform the data and make it ready for modeling.\n",
        "\n",
        "**Transformation and Shapes**:\n",
        "- After preprocessing, the training data has been transformed into a format suitable for the machine learning model, with 59054 samples and 807 features after one-hot encoding of categorical variables.\n",
        "- The preprocessed data occupies roughly 381 million bytes, or 362 MB, which is large but manageable for most modern systems.\n",
        "\n",
        "**Cleanup**:\n",
        "- To ensure efficient memory usage, we removed the original data from memory and collected garbage.\n",
        "\n",
        "**Preprocessing Time**:\n",
        "- The whole process took a little over 5 seconds, indicating that our preprocessing pipeline is fairly efficient.\n",
        "\n",
        "By meticulously preparing our data, we've made sure it's in the best shape to be used by our algorithms, maximizing our chances of accurately detecting fraud."
      ],
      "metadata": {
        "id": "J94ij7Zknq8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Machine Learning Models and Performance Analysis for Fraud Detection\n",
        "\n",
        "**Implemented Models**:\n",
        "1. **Logistic Regression**\n",
        "2. **Decision Tree**\n",
        "3. **Random Forest**\n",
        "4. **XGBoost (Extreme Gradient Boosting)**\n",
        "\n",
        "**Model Outputs & Implications**:\n",
        "\n",
        "- **Logistic Regression**:\n",
        "  - It demonstrated moderate accuracy.\n",
        "  - Precision was high, indicating that when it predicted fraud, it was often correct.\n",
        "  - The recall was low, meaning it missed a fair number of fraudulent transactions.\n",
        "  - The model is good as a baseline but might not catch as much fraud as we'd like.\n",
        "\n",
        "- **Decision Tree**:\n",
        "  - It showed excellent performance on training data but lower validation accuracy, a sign of overfitting.\n",
        "  - It had fair recall and precision on validation data, but the balance between detecting fraud and distinguishing legitimate transactions could be better.\n",
        "\n",
        "- **Random Forest**:\n",
        "  - Achieved very high accuracy, precision, and recall scores, suggesting it is very good at identifying fraudulent transactions without many false positives.\n",
        "  - It was less prone to overfitting compared to the Decision Tree and maintained strong performance on unseen data.\n",
        "  \n",
        "- **XGBoost**:\n",
        "  - It also provided high accuracy and balanced precision and recall scores.\n",
        "  - Its performance was strong on both training and validation sets, making it a robust model for detecting fraudulent transactions.\n",
        "  \n",
        "  \n",
        "![image.png](attachment:16bbf0a2-f546-4d0f-8d17-881ebcd137b0.png)\n",
        "\n",
        "**What the Analysis Tells Us**:\n",
        "The Random Forest and XGBoost models emerged as the most effective at predicting fraudulent transactions, balancing the need to catch fraud with the importance of not flagging too many legitimate transactions as fraudulent. These models are well-suited for further refinement and potentially for deployment in a fraud detection system due to their strong and balanced performance metrics."
      ],
      "metadata": {
        "id": "rPEPGgSOnq8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion for Fraud Detection Using Machine Learning\n",
        "\n",
        "Throughout this project, we have approached the challenge of online fraud detection by implementing and evaluating several machine learning models. Our efforts revealed valuable insights into model performance and their capabilities in distinguishing between fraudulent and legitimate transactions.\n",
        "\n",
        "**Key Takeaways**:\n",
        "- **Model Selection**: Among the models tested, Random Forest and XGBoost demonstrated the most promise, providing high accuracy and a strong balance between sensitivity (recall) and precision.\n",
        "- **Model Evaluation**: Precision, recall, and F1-scores were key metrics used to evaluate model performance, with a particular focus on recall to ensure the detection of as many fraudulent transactions as possible.\n",
        "- **Data Handling**: Efficient data preprocessing was vital in handling missing values, scaling features, and encoding categorical variables, enabling the models to learn from a clean and informative dataset.\n",
        "\n",
        "**Final Thoughts**:\n",
        "The success of the Random Forest and XGBoost models indicates that machine learning can be an effective tool in combating fraud. However, the journey does not end here. Continuous refinement and model updating are necessary to adapt to evolving fraudulent activities. Moreover, deploying these models into a real-world system would require additional integration and monitoring to maintain performance over time.\n",
        "\n",
        "For more details on the methodology, implementation, and results, you can visit the [Kaggle notebook](https://www.kaggle.com/code/rishitharishitha/ieee-fraud-detection/).\n",
        "\n",
        "This project underscores the potential of machine learning in enhancing online transaction security and represents a significant step forward in the fight against financial fraud."
      ],
      "metadata": {
        "id": "fKEGkGWdnq80"
      }
    }
  ]
}